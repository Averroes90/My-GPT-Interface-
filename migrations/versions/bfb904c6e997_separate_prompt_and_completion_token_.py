"""Separate prompt and completion token counts

Revision ID: bfb904c6e997
Revises: 
Create Date: 2024-01-22 15:12:25.143983

"""
from alembic import op
import sqlalchemy as sa
from utils.utils import count_tokens
from models import Interaction
# revision identifiers, used by Alembic.
revision = 'bfb904c6e997'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # Create a temporary SQLAlchemy context
    bind = op.get_bind()
    session = sa.orm.Session(bind=bind)

    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('interaction', schema=None) as batch_op:
        batch_op.add_column(sa.Column('prompt_token_count', sa.Integer(), nullable=True))
        batch_op.add_column(sa.Column('response_token_count', sa.Integer(), nullable=True))

    # Populate the new columns
    interactions = session.query(Interaction).all()
    for interaction in interactions:
        interaction.prompt_token_count = count_tokens(interaction.prompt, interaction.model_name)
        interaction.response_token_count = count_tokens(interaction.response, interaction.model_name)
        session.add(interaction)
    session.commit()

    # Alter the new columns to be non-nullable
    with op.batch_alter_table('interaction', schema=None) as batch_op:
        batch_op.alter_column('prompt_token_count', existing_type=sa.Integer(), nullable=False)
        batch_op.alter_column('response_token_count', existing_type=sa.Integer(), nullable=False)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    
    with op.batch_alter_table('interaction', schema=None) as batch_op:
        batch_op.alter_column('prompt_token_count', existing_type=sa.Integer(), nullable=True)
        batch_op.alter_column('response_token_count', existing_type=sa.Integer(), nullable=True)

    
    with op.batch_alter_table('interaction', schema=None) as batch_op:
        batch_op.drop_column('response_token_count')
        batch_op.drop_column('prompt_token_count')

    # ### end Alembic commands ###
